[{"content":"","permalink":"https://sinanthahir.github.io/","title":""},{"content":"Winning Space Race with Data Science Space-X Landing Prediction is an Applied Data Science Capstone Project done as part of IBM Data Science Certification Program. Objective The goal of this project is to provide analysis on SpaceX launches, with focus on stage reuse and landings, to provide our company, SpaceY, competitive information on cost of launches and prediction methods on whether SpaceX will reuse a given stage.\nMethodology  Data collection:  SpaceX API: Past landing data, plus info on boosters, cores, payloads; Wikipedia scrape: Parse tables of past launches (including outcomes ‚Äî success/failure) into a DataFrame for next stage.   Data wrangling:  Outcomes (‚ÄúTrue ASDS‚Äù, ‚ÄúTrue Ocean‚Äù, etc.) grouped into two classes ‚Äî success (1) and failure (0); Column ‚Äòclass‚Äô added to DataFrame, to be used for model building and prediction.   Exploratory data analysis (EDA) using Visualization and SQL:  Data loaded into IBM Cloud DB2 instance; SQL queries run from Jupyter notebook; Plotly and Seaborn; categorical plots (scatter, bar, line); One-hot encoding of features.   Interactive visual analytics using Folium and Plotly Dash:  Folium maps + marker clusters: show launch sites; Dashboard: show successes for all launch sites, success percentage per site, and payload per launch.   Predictive analysis using classification models:  Split data between training and testing; Train and test 4 models: LogReg (logistic regression), SVM (support vector machine), Tree (decision tree), KNN (K nearest neighbors); Grid Search with a set of hyperparams; check model scores (R^2); build confusion matrix for each; ‚Äî\u0026gt; select best model.    Conclusions (Predictive Model)  Out of 4 prediction models (LogReg, SVM, Tree, KNN), SVM had the best accuracy on training data, and among the best at scores on test data. The Tree model appeared the weakest. Test vs Training data accuracy are not the same. The dataset is too small (only 90 observations) to distinguish any further between these models  See the Results üëá üìÅ Source Files üìù Report üåê Dashboard\n","permalink":"https://sinanthahir.github.io/showcase/spacex/","title":"Space X Landing Prediction"},{"content":"Experience Analysis through Weather Data Knowing accurate weather conditions is an important element for individuals as well as organizations. Many businesses rely on weather conditions. It is necessary to have the correct data to get accurate decisions. One type of data that‚Äôs easier to find on the internet is Weather data. Many sites provide historical data on many meteorological parameters.\n The Analysis project was done as a part of my Data Analytics Internship at Suven Consultants \u0026amp; Technology.\n Objective The main objective is to perform data cleaning, perform analysis for testing the Influences of Global Warming on temperature and humidity, and finally put forth a conclusion.\nHypothesis The Null Hypothesis H0 is ‚ÄúHas the Apparent temperature and humidity compared monthly across 10 years of the data indicate an increase due to Global warming‚Äù ‚Äî That means we need to find whether the average Apparent temperature for the month of a month says April starting from 2006 to 2016 and the average humidity for the same period have increased or not.\nSee the Results üëá üìÅ Source Files üìù Report\n","permalink":"https://sinanthahir.github.io/showcase/weather/","title":"Weather Data Analysis"},{"content":"Industrial Product Design Mostly these are free time activity, turn out to be a full fledge concepts.\n Drone Design : SiniGator-X Sinigator-X is a Quadcopter Design submitted for the TechFest 2018 conducted by IIT Bombay. Design was made up with the rotor base at 135 Deg Axis-Planned, X factored and was complimented for the best endurance factor and seamless flight dynamics by the Jury.\nTo check out the full design, üëâ Click Here\n Among Us - Table Decor Light Lamp  For those who are playing Among Us !\n Lets widen your table space with Among Us - Table Light, which has as far as lumen 400 light source. The Concept design was modelled using Dassault\u0026rsquo;s Solidworks and Rendered Using Keyshot 9 Pro.\nTo check out the full design, üëâ Click Here\n Nissan GTR Mockups  Model Designing \u0026amp; Realistic Rendering\n To check out the full design, üëâ Click Here\n 3D Cartesian Printer  Model Designing \u0026amp; Product Rendering\n To check out the full design, üëâ Click Here\n","permalink":"https://sinanthahir.github.io/showcase/industrial-products/","title":"Industrial Product Designs"},{"content":"Branding And Promotional Mostly these designs and promo activities are done as a part of Community events, Collegiative Events and Startup marketing.\n Itiha 2K18 Itiha 2K18, National Techno-Cultural Fest of Rajadhani Institute of Engineering and Technology, Trivandrum hosted on March 8th, 9th and 10th, 2018. I was one among the designers and collaborator in the media and promotional club.\n   ITIHA 2K19  #the_ecstacy_of_culture\n It was a great opportunity to work for the second time in the designing and media committee of our fest. Had been one of the prior designer under the lead by Rahul Raj SR, Committee Head. Here are some of my best piece of work.\n Pratheeka 2019 - The annual college magazine. It was a great opportunity to create the face of Pratheeka 2019 - The annual college magazine. Representing as a cover designer as well as a core designer with the blessings as a team of 15, we were able to publish the hardcopies within the summerfall of 2019.\n Salaa Boutique  Logo Retouch and Flyer Design For Salaa Boutique\n  You can check out more of the design concepts and models @behance/sinanthahir ","permalink":"https://sinanthahir.github.io/showcase/branding-and-promotional/","title":"Branding And Promotional"},{"content":"You can find notes from the books i love to some scribbles, what ever thoughts; i pen down.\n","permalink":"https://sinanthahir.github.io/bookshelf/","title":"Bookshelf"},{"content":"heay alll ","permalink":"https://sinanthahir.github.io/bookshelf/100solitude/","title":"One Hundread Days of Solitude"},{"content":"Sharing some of my learning notes, articles, community experiences, talk and tech perspectives.\n","permalink":"https://sinanthahir.github.io/blogs/","title":"Blogs"},{"content":"","permalink":"https://sinanthahir.github.io/tags/data-science/","title":"Data Science"},{"content":"Learn Data Science : Even when you are broke Since the Harvard Bussiness Review quoted ‚ÄúData Scientist: The Sexiest Job of the 21st Century‚Äù, the rose in demand for data scientist and machine learning expert is unimaginable.\nWhy \u0026amp; What is Data Science ? If you will look around, the majority of the companies are running around for data. Some are looking for the user‚Äôs personal data whereas some are looking for professional details of the user. For the last decade, every company needs data in order to sell their products. Data comes in handy in several industrial processes. Products are being developed after proper data analysis of different users.\nData Science is one of the most in-demand skills in the current technology world and all kinds of companies are looking for accomplished Data Scientists to make sense of the massive data they are collecting every day to increase sales, profit, and overall business process.\nNowadays many institutes and e-learning platforms are bringing up top notch Master‚Äôs/Professional degree programs with a cost worth of $6,000. Since completing my bachelor‚Äôs that too; a specialization in mechanical engineering, the broke mind didn‚Äôt compel me. So, I gone the other way around, that is too Self Learn.\n More over my instincts, the best way to learn is to experience \u0026amp; understand what you learn by practice.\n If you are looking for a career in this field, you need to learn the basics of data analysis and if you need resources you have come to the right place.\nHere, I will be sharing my learning path and material which helped me to land in my first job, that too as a Research Analyst. All these courses are free and the best in their class. Besides this, all these courses are trusted by hundreds of students and have high ratings.\nüìä Path to a free self-taught education in Data Science! As you had seen from the above image, to learn data science; knowing about the theory behind the process, the technical needed to drive the process and the method to curate the insights.\nGenerally a wish bone knowledge in Both Math-Statistics \u0026amp; Programming can help you fasten the seat belt to data science. Luckily, I had to go through both. lol ü§£\n1. Introduction to Data science This will be a introductory level course you need to know about skills that will help you filter out the most important data from a pile of unwanted data. This course will help you develop these skills, besides this, you will learn about data science and its history.\nCourse Link üëâ Click Here\n2. Math \u0026amp; Statistics Math and Statistics for Data Science are essential because these disciples form the basic foundation of all the Machine Learning Algorithms. In fact, Mathematics is behind everything around us, from shapes, patterns, count and colors.\nI will suggest these two courses;\nCalculus 101 | Khan Academy üëâ Click Here\nSingle Variable Calculus | MIT Opensources üëâ Click Here\n2.2 Linear Algebra Many popular machine learning methods, including XGBOOST, use matrices to store inputs and process data. Matrices alongside vector spaces and linear equations form the mathematical branch known as Linear Algebra. In order to understand how many machine learning methods work it is essential to get a good understanding of this field.\nI will suggest these two courses;\nLinear Algebra | Khan Academy üëâ Click Here\nLinear Algebra | MIT Opensources üëâ Click Here\n2.3 Multivariable Calculus In data science, while looking out for relations between function and factors, we can observe varying dependencies of the factors. Many data science \u0026amp; machine learning algorithms utilize multivariable calculus to optimize the performance of models.\nI suggest these two courses;\nMultivariable Calculus | Khan Academy üëâ Click Here\nMultivariable Calculus | MIT Opensources üëâ Click Here\n2.4 Statistics and Probability If there is one thing that I can be the most confident about my Mechanical Engineering background, it would be a rigorous and solid Math and Stats Foundations. In the midst of the hype around data-driven decision making, the basics are somehow getting sidelined. The boom in data science requires an increase in executive statistics and maths skills. Some of the fundamental concepts expected from a business analyst are correlation, causation and how to statistically test hypothesis.\n  I also suggest these two courses;\nBusiness Statistics and Analysis | Coursera üëâ Click Here\nStatistics and Probability | Khan Academy üëâ Click Here\nThat will be all for Math, I could recommend with beginning phase. But as you move along, day by day newer techniques will be learned.\n3. Computer Science Isle 3.1. Computer Science Principles Program or code runs on a computer and uses CPU,RAM, input/output devices. This goes over all these basic principals of computer science. Data is stored as bits (1s and 0s) in RAM and disk. The course will also go over fundamentals of binary numbers. In this course only follow first 4 sections (1) Digital Information (2) The Internet (3) Programming (4) Algorithms. Completing remaining sections is optional and do it if you have time and interest.\nThese two courses will provide you with the resources, a little googling can make a big return too;\nAP CS Principles | Khan Academy üëâ Click Here\nIntro to CS and Programming using Python | Edx üëâ Click Here\n3.2. Data structures and Algorithms There is not a single programming interview where they don‚Äôt ask about data structures and algorithms (a.k.a DSA). DSA are fundamental building blocks of any program (doesn‚Äôt matter which programming language). Follow this playlist to get your data structure and algo concepts clear.\n  I also prefer, this course to understand the basics;\nAlgorithms, Part I | Coursera üëâ Click Here\n3.3. Databases (SQL) Doesn‚Äôt matter which career track you choose, you need to have good understanding of relational databases and SQL (structured query language). Here are some course links for SQL. Literally, SQL Master is one of the best hat you can wear while working in such roles - my experience to say.\nI will suggest these three, of different kinds;\nDatabase Management Essentials | Coursera üëâ Click Here\nIntro to SQL | Khan Academy üëâ Click Here\nCheck this awesome playlist to learn about from installation to basic exercises for SQL Server.\n  4. Data Science Tools and Methods Data scientists apply some operational methods, which are called the techniques on the data through various software, which are known as tools. This combination is used in acquiring data, refining it for the purpose intended, manipulating and labeling, and then examining the results for the best possible outcomes.\nTools for Data Science | Coursera üëâ Click Here\nWhich programming languages should I use? Python and R are heavily used in Data Science community. Remember, the important thing for each course is to internalize the core concepts and to be able to use them with whatever tool (programming language) that you wish. I prefer Python more, I had seen more people opting it.\nPython For Data Science | Great Learning üëâ Click Here\n     5. Machine Learning \u0026amp; Data Mining Many people do the mistake of learning every algorithm in ML and forget where it actually helps in solving a problem. For beginners, it is suggested that they learn the popular and standard algorithms. A complicated algorithm is not always the solution for complex applications. It is all about how an ML problem is solved optimally.\nI will suggest these two;\nML Crash Course | Google Developers üëâ Click Here\nMachine Learning | Coursera üëâ Click Here\n You can Audit the Courses on Coursera and Edx for free access to the content. If you wish to obtain a certificate; go for the certified plans. Most of the Youtube series choosed are from Code Basics - because i love the way he represents concepts, ideation for projects \u0026amp; interviews with many data science professional.\n üö® Useful Tips Please watch this video to understand how you can learn effectively so that you can get maximum output by investing minimum amount of time.\n  Following discipline and not giving up Learning coding, especially when you are new, can get frustrating at times. Every good programmer has gone through this pain so if you are facing issues, don‚Äôt start thinking you are not smart and coding is not your thing. You need to have lot of patience. When you come from non coding background, thinking in terms of coding is a big shift in the mind paradigm hence it can take some time before it starts clicking you.\n  If you have any queries regarding any topics, feel free to connect with me. Kindly share among your colleague, it may be helpful for them.\n   The Article was also published on my Medium Space.\n","permalink":"https://sinanthahir.github.io/blogs/learn-ds-even-when-broke/","title":"Learn Data Science: Even when you are broke!"},{"content":"","permalink":"https://sinanthahir.github.io/tags/learning/","title":"Learning"},{"content":"","permalink":"https://sinanthahir.github.io/tags/mathematics/","title":"Mathematics"},{"content":"","permalink":"https://sinanthahir.github.io/tags/ml/","title":"ML"},{"content":"","permalink":"https://sinanthahir.github.io/tags/statistics/","title":"Statistics"},{"content":"","permalink":"https://sinanthahir.github.io/tags/","title":"Tags"},{"content":"","permalink":"https://sinanthahir.github.io/tags/analytics/","title":"Analytics"},{"content":"Machine Learning for Recognizing Handwritten Digits Machine learning is a field of artificial intelligence in which a system is designed to learn automatically given a set of input data. After the system has learnt (we say that the system has been trained), we can use it to make predictions for new data, unseen before. This approach makes it possible to solve complex problems which are difficult or impossible to solve with traditional sequential programming.\nRecognizing handwritten text is a problem that traces back to the first automatic machines that needed to recognize individual characters in handwritten documents. Think about, for example, the ZIP codes on letters at the post office and the automation needed to recognize these five digits. Perfect recognition of these codes is necessary to sort mail automatically and efficiently. Included among the other applications that may come to mind is OCR (Optical Character Recognition) software. OCR software must read handwritten text, or pages of printed books, for general electronic documents in which each character is well defined. But the problem of handwriting recognition goes farther back in time, more precisely to the early 20th Century (the 1920s), when Emanuel Goldberg (1881‚Äì1970) began his studies regarding this issue and suggested that a statistical approach would be an optimal choice.\nIn this project, our goal is to get started hands on with machine learning to recognize this handwrittens, so I‚Äôm only going to give you a simplified explanation for now.\r\rThe above network displays a network of successive training sets, which consists of the image of a digit \u0026amp; a label, which tells us what the image truly represents.\nAt first, the first image is processed by the neural network and produces an answer: that is a 9. The connections of neurons in the network be in randomly stated and is providing anything useful, just a random answer.\nThe answer is compared to the label. Here, the value of (9) is actually different from the label, i.e the value (3). Some feedback is given back such that the network can improve, favoring in tend to give a correct answer.\nThen the next example are considered and the neural network learns in such iterative way.\nAim: The primary aim of this project involves predicting a numeric value, and then reading and interpreting an image that uses a handwritten font.\nHypothesis: The Digits data set of the scikit-learn library provides numerous datasets that are useful for testing many problems of data analysis and prediction of the results. Some Scientist claims that it predicts the digit accurately 95% of the times. Perform data Analysis to accept or reject this Hypothesis.\n Here, I will be using Anaconda Kernel Interpreted VS Code Environment and using Python libraries like Matplotlib, Seaborn, Scikit-Learn.\n The Digits Dataset: The scikit-learn library provides many datasets that are useful for testing many problems of data analysis and prediction of the results. Also in this case there is a dataset of images called Digits. This dataset comprises 1,797 images that are 8x8 pixels in size. Each image is a handwritten digit in grayscale.\nImporting Dataset Import datasets module from sklearn library and load the digits dataset using the load_digits() function.\nfrom sklearn import datasets\rdigits = datasets.load_digits()\rDescription of Dataset After loading the dataset, we can read the information about the dataset by calling the DESCR attribute.\nprint(digits.DESCR)\rThe textual description of the dataset, the authors who contributed to its creation, and the references will appear as shown in the output.\nEach dataset in the scikit-learn library has a field containing all the information.\nTargets The numerical values represented by images, i.e., the targets, are contained in the digit.targets array.\ndigits.target\rOutput:\rarray([0, 1, 2, ..., 8, 9, 8])\rDataset Shape Dimensions of the dataset can be obtained using data.shape() function.\ndigits.data.shape\rOutput:\r(1797, 64)\rThe output shows that the dataset has 1797 images of 8x8 size(i.e, 8 * 8 = 64 px). In other words, this array could be represented in 3D as a pile of images with 8x8 pixels each.\nImages of the handwritten digits The images of the handwritten digits are contained in an array. Each element of this array is an image that is represented by an 8x8 matrix of numerical values that correspond to grayscale from white, with a value of 0, to black, with the value 15.\nLet‚Äôs look at the data of the first 8x8 image. Each slot in the array corresponds to a pixel, and the value in the slot is the amount of black in the pixel.\ndigits.images[0]\rVisualization of an array We can visually check the contents of this result. The following steps can get it done\n Import pyplot module which is under matplotlib as plt. The imshow() function is used to display data as an image; i.e. on a 2D regular raster. cmap = gray_r displays a grayscale image. interpolation= ‚Äònearest‚Äô displays an image without trying to interpolate between pixels if the display resolution is not the same as the image resolution. The title() function is used to display the title on the graph.  import matplotlib.pyplot as plt\rplt.imshow(digits.images[0], cmap=plt.cm.gray_r, interpolation='nearest')\rplt.title('one of the 1797 handwritten digits')\rplt.savefig('plot1.png', dpi=100, bbox_inches='tight')\rBy running this command, we will obtain the grayscale image as follows: Visualization of 10 digits Using the NumPy and matplotlib libraries, we can display each digit from 0 to 9 which are in the form of an array as images.\n The figure() function in the pyplot module of the matplotlib library is used to create a new figure with a specified size of (15,4). subplots_adjust(hspace=0.8) is used to adjust the space between the rows of the subplots. Combine two lists using the zip() function for easier handling inside the plotting loop. enumerate() method adds a counter to an iterable and returns it. The returned object is a enumerate object. subplot() function is used to add a subplot to a current figure at the specified grid position.  import numpy as np plt.figure(figsize=(15,4))\rplt.subplots_adjust(hspace=0.8)images_and_labels = list(zip(digits.images, digits.target)) for index, (image, label) in enumerate(images_and_labels[:10]): plt.subplot(2, 5, index + 1) plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest') plt.title('Training: %i' % label, fontsize =12)\rplt.savefig('plot2.png', dpi=300, bbox_inches='tight')\rFlatten the input images The inputs are 8x8 grayscale images. we can produce a flat array of 64-pixel values so that each pixel corresponds to a column for the classifier.\n len() function gives the number of images in the dataset. reshape() function returns an array containing the same data with a new shape.  n = len(digits.images)\rprint(n)\rdata = digits.images.reshape((n, -1))\rOutput:\r1797\rIt was reported that the dataset is a training set consisting of 1,797 images. We determined that it is true.\nThe Machine Learning Model An estimator that is useful in this case is sklearn.svm.SVC, which uses the technique of Support Vector Classification (SVC).\n‚ÄúSupport Vector Machine‚Äù (SVM) is a supervised machine learning algorithm that is mostly used in classification problems.\n You can read more about SVM model from Scikit-Learn‚Äôs Official Document.\n Import the SVM module of the scikit-learn library and create an estimator of SVC type and then choose an initial setting, assigning the values C and gamma generic values.\n#import svm model\rfrom sklearn import svm\r#Create a SVMClassifier\rsvc = svm.SVC(gamma=0.001, C=100.)\rSplit the Dataset once we define a predictive model, we must instruct it with a training and test set. The training set is a set of data in which you already know the belonging class and the test set is a secondary data set that is used to test a machine learning program after it has been trained on initial training.\nImport train_test_split() function which is used for splitting data arrays into two subsets i.e., into train and test sets.\nHere we have split the data by assigning 0.01 as test size.\nfrom sklearn.model_selection import train_test_split\rx_train, x_test, y_train, y_test = train_test_split(data, digits.target, test_size=0.01, random_state=0)\rTrain the model we can train the svc estimator that we defined earlier using the fit() function.\nAfter a short time, the trained estimator will appear with text output.\nsvc.fit(x_train, y_train)\rOutput:\rSVC(C=100.0, gamma=0.001)\rTest the model we can test our estimator by making it interpret the digits of the test set using predict() function.\ny_pred = svc.predict(x_test)\ry_pred\rOutput:\rarray([2, 8, 2, 6, 6, 7, 1, 9, 8, 5, 2, 8, 6, 6, 6, 6, 1, 0])\rWe obtain the results in the form of an array.\nVisualize the test images We can plot the images of the predicted digits from the array using the following code.\nimages_and_predictions = list(zip(x_test,y_pred))\rplt.figure(figsize=(18,5))\rfor index, (image, prediction) in enumerate(images_and_predictions[:19]):\rplt.subplot(2, 9, index + 1)\rimage = image.reshape(8, 8)\rplt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\rplt.title('Prediction: %i' % prediction)\r# save the figure\rplt.savefig('plot3.png', dpi=300, bbox_inches='tight')\rIt is able to recognize the handwritten digits and interprete all the digits of the validation set correctly.\nAccuracy of the model The accuracy score of the model can be obtained using the score() function.\nscore = svm.score(x_test, y_test)\rOutput:\rAccuracy Score: 1.0\rConfusion Matrix A confusion matrix is a table that is often used to describe the performance of a classification model (or ‚Äúclassifier‚Äù) on a set of test data for which the true values are known.\n#For Confusion Matrix\rfrom sklearn.metrics import confusion_matrix\rimport pandas as pd\rimport seaborn as sn data = confusion_matrix(y_test, y_pred)\rdf_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\rdf_cm.index.name = 'Actual'\rdf_cm.columns.name = 'Predicted' plt.figure(figsize = (10,10))\rsn.set(font_scale=1.4)#for label size\rplt.title('Confusion Matrix')\rsn.heatmap(df_cm, annot=True,annot_kws={\u0026quot;size\u0026quot;: 12})# font size\rA Classification report is used to measure the quality of predictions from a classification algorithm.\nConclusion Given the large number of elements contained in the Digits dataset, we will certainly obtain a very effective model, i.e., one that‚Äôs capable of recognizing with good certainty.\nWe test the hypothesis by using these cases, each case for a different range of training and validation sets.\nAfter performing the data analysis on the dataset with three different test cases, we can conclude that the given hypothesis is true i.e., the model predicts the digit accurately 95% of the times.\n You can find Source code: github@sinanthahir\n ","permalink":"https://sinanthahir.github.io/blogs/recognizing-handwritten-digits/","title":"Machine Learning for Recognizing Handwritten Digits"},{"content":"","permalink":"https://sinanthahir.github.io/tags/scikit-learn/","title":"Scikit Learn"},{"content":"","permalink":"https://sinanthahir.github.io/tags/eda/","title":"EDA"},{"content":"Experience Analysis through Weather Data : Exploratory Data Analysis Knowing accurate weather conditions is an important element for individuals as well as organizations. Many businesses rely on weather conditions. It is necessary to have the correct data to get accurate decisions. One type of data that‚Äôs easier to find on the internet is Weather data. Many sites provide historical data on many meteorological parameters.\nExploratory Data Analysis is an approach to analyze data, to summarize the main characteristics of data, and better understand the data set. It also allows us to quickly interpret the data and adjust different variables to see their effect. The three main steps to get a perfect EDA are extracting the data from an authorized source, cleaning and processing the data, and performing data visualization on the cleaned data set.\nHere, I will work through out a practical exploratory data analysis which was done a part of my data analytics internship at Suven Consultants \u0026amp; Technology.\nObjective: The main focus of our project was to perform analysis for testing the Influences of Global Warming and finally put forth a conclusion.\nHypothesis: A hypothesis is an assumption, an idea that is proposed for the sake of argument so that it can be tested to see if it might be true. The Null Hypothesis H0 is ‚ÄúHas the Apparent temperature and humidity compared monthly across 10 years of the data indicate an increase due to Global warming‚Äù\r\rThat means we need to find whether the average Apparent temperature for the month of a month says April starting from 2006 to 2016 and the average humidity for the same period have increased or not.\n So, What is this Apparent Temperature and Humidity mentioned in the Null Hypothesis (H0)?\n These are called Terminologies, or rather say the column names or criteria used to constrain the data we have to different specification or class. In order to know that we must look up for basic terminologies used in the data we are working on.\nTerminologies: Meteorological Data refers to data consisting of physical parameters that are measured directly by instrumentation, and include temperature, dew point, wind direction, wind speed, cloud cover, cloud layer(s), ceiling height, visibility, current weather, and precipitation amount.\nApparent temperature is the temperature equivalent perceived by humans, caused by the combined effects of air temperature, relative humidity, and wind speed. The measure is most commonly applied to the perceived outdoor temperature.\nHumidity is the amount of water vapor in the air. If there is a lot of water vapor in the air, the humidity will be high. The higher the humidity, the wetter it feels outside.\n You can check out more weather terminologies from Kestrelmeter‚Äôs Glossary.\n Dataset: The dataset currently using, can be obtained from Kaggle. The dataset has hourly temperature recorded for the last 10 years starting from 2006‚Äì04‚Äì01 00:00:00.000 +0200 to 2016‚Äì09‚Äì09 23:00:00.000 +0200. It corresponds to Finland, a country in Northern Europe.\n Now, we have our Objective, Dataset, and basic understanding of the Terminologies. So let‚Äôs start of journey to analyze the data!\n Data Preprocessing Here, i‚Äôm using Anaconda Environment with Visual Studio Code. You can also set up such a system which enable a faster git and pipeline integration.\nImporting required libraries: We will be using Python libraries such as Pandas, Numpy, Matplotlib and Seaborn.\nimport numpy as np\rimport pandas as pd\rimport matplotlib.pyplot as plt\rimport seaborn as sns\rLoading dataset: Load the dataset using read_csv() function as the dataset is in CSV form and read the first 5 rows from data using head() function.\ndata = pd.read_csv('weatherHistory.csv')\rdata.head()\rDimensions of the dataframe refers to the overall data sample, i.e, the total number of rows and columns in the data. It can be obtained using data.shape function as follows\ndata.shape\rThe total number of rows and columns in the data set is 96453 and 12 respectively.\nTo find out the types and overall summary of the data frame, we use the data.info() function. It comes in handy when doing exploratory analysis of the data.\ndata.info()\rWe can use the describe() function to get the descriptive statistical details of the data-frame.\ndata.describe()\rTo check the distinct elements in the data frame, we can use the nunique() function.\ndata.nunique()\rWe can check for any missing values using the isnull() function. since having a large dataset, we can incorporate sum() function to get the total number of missing value in each columns.\ndata.isnull().sum()\rTill now, we had got up many details about the dataset we are working on. Lets take it into account.\nObservations:  In ‚ÄòPrecip Type‚Äô, there are 517 missing values. ‚ÄòWind Bearing (degrees)‚Äô has only integer values. Formatted Date is in String. Minimum values of Humidity, Wind Speed (km/h), Wind Bearing (degrees), Visibility (km) are Zero and they can be Zero. From Statistical details and Distinct Elements in Dataframe, It is noticed that ‚ÄôLoud Cover‚Äô are zero or null.  We can remove the unwanted columns which don‚Äôt add value to the analysis using the drop() function. We will drop ‚ÄòLoud Cover‚Äô as it has one unique value 0 and it is not useful in analysis.\ndata = data.drop([‚ÄòLoud Cover‚Äô], axis = 1)\rCorrelation of the Columns: Correlation matrices are an essential tool of exploratory data analysis. We can display the pairwise correlation using corr() function which creates the correlation matrix between all the features in the dataset. Correlation heatmaps contain the same information in a visually appealing way.\n# assign data correlation matrix\rrelation = data.corr()\r# Increase the size of the heatmap\rplt.figure(figsize=(10,8))\r# Store heatmap object in a variable to easily access it\rwhen you want to include more features and you can set the annotation parameter to True to display the correlation values on the heatmap.\rsns.heatmap(data=relation)\r# Give a title to the heatmap.\rplt.title(\u0026quot;Correlation of columns in the dataframe\u0026quot;)\r# save the figure.\rplt.savefig('plot1.png', dpi=300, bbox_inches='tight')\rplt.show()\rObservation: From the Pairwise correlation chart, we can see that Apparent Temperature and Humidity have a high degree of correlation with each other. So we have a high chance of validating our hypothesis.\nWe only need 3 columns for checking and validating our task which is data [‚ÄòFormatted Date‚Äô, ‚ÄòApparent Temperature(c)‚Äô, ‚ÄòHumidity‚Äô]. So, we can ignore other columns and missing values.\nParsing Dates, Creating new dataframe : Change the ‚ÄòFormatted Date‚Äô feature from String to Datetime using the datetime() function.\ndata[‚ÄòFormatted Date‚Äô] = pd.to_datetime(data[‚ÄòFormatted Date‚Äô],utc=True)\rWe can set ‚ÄúFormatted Date‚Äù as an index using the set_index() function which sets the DataFrame index (row labels) using one or more existing columns.\ndata = data.set_index(‚ÄúFormatted Date‚Äù)\rdata.info()\rResampling Data: Resampling is a convenient method for frequency conversion. The object must have a datetime like an index.\nNow, we have hourly data, we need to resample it to monthly. We only require the Apparent Temperature and humidity columns to test the hypothesis. So, we will consider these two columns and perform a resample() function from Pandas.\ndf_column = ['Apparent Temperature (C)', 'Humidity']\rdf_monthly_mean = data[df_column].resample(\u0026quot;MS\u0026quot;).mean() #MS-Month Starting\rdf_monthly_mean.head()\rNow, we converts hourly data to monthly data using ‚ÄúMS‚Äù which denotes the Month starting. We are displaying the average apparent temperature and humidity using the mean() function.\n We are done with cleaning and resampling it. Now, Lets begin our analysis.\n Relation between Apparent Temperature \u0026amp; Humidity Using Regression: We can use the regplot() function to plot the relationship between the ‚ÄúApparent Temperature ‚Äù and ‚ÄúHumidity‚Äù.\n# calling regplot function and assign it with our data and plot labels and color parameter.\rsns.regplot(data=df_monthly_mean, x=\u0026quot;Apparent Temperature (C)\u0026quot;, y=\u0026quot;Humidity\u0026quot;, color=\u0026quot;r\u0026quot;)\r# Give a title to the plot\rplt.title(\u0026quot;Relation between Apparent Temperature (C) and Humidity\u0026quot;)\r# save the figure\rplt.savefig('plot2.png', dpi=300, bbox_inches='tight')\rplt.show()\rObservation: There is a Linear Relation between ‚ÄúApparent Temperature ‚Äù and ‚ÄúHumidity‚Äù with a negative slope.\nAs air temperature increases, air can hold more water molecules, and its relative humidity decreases. When temperatures drop, relative humidity increases.\nYearly Variation of Apparent Temperature and Humidity: We use lineplot() function to plot the Variation of Apparent Temperature and Humidity with time.\nplt.figure(figsize=(15,7))\rsns.lineplot(data= df_monthly_mean)\rplt.xlabel('year')\rplt.title('Variation of Apparent Temprature and HUmidity with Time')\rplt.savefig('plot3.png', dpi=300, bbox_inches='tight')\rplt.show()\rThe above graph displays average temperature and humidity for all 12 months over the 10 years i.e., from 2006 to 2016.\nObservation:  ‚ÄúHumidity‚Äù remained constant from 2006‚Äì2016 ‚ÄúApparent Temperature‚Äù changed from 2006‚Äì2016 at regular intervals with constant amplitude.  Variation of Humidity \u0026amp; Apparent Temperature for all months: Creating a function which labels each month number with actual month name and a specified color for graph. and defining a seaborn plot() function. This function helps to analyze the variations in Apparent Temperature and Humidity for all months over the 10 years.\n# Defining a function call for month to be labeled\rdef label_color(month):\rif month == 1:\rreturn 'January','black'\relif month == 2:\rreturn 'February','brown'\relif month == 3:\rreturn 'March','red'\relif month == 4:\rreturn 'April','orange'\relif month == 5:\rreturn 'May','yellow'\relif month == 6:\rreturn 'June','blue'\relif month == 7:\rreturn 'July','violet'\relif month == 8:\rreturn 'August','pink'\relif month == 9:\rreturn 'September','grey'\relif month == 10:\rreturn 'October','pink'\relif month == 11:\rreturn 'November','purple'\relse:\rreturn 'December','green'\r# Assigning variables to resampled data\rTEMP_DATA = df_monthly_mean.iloc[:,0]\rHUM_DATA = df_monthly_mean.iloc[:,1]\rdef plot_month(month, data):\rlabel, color = label_color(month)\rmdata = data[data.index.month == month]\rsns.lineplot(data=mdata,label=label,color=color,marker='o')\rdef sns_plot(title, data):\rplt.figure(figsize=(14,8))\rplt.title(title)\rplt.xlabel('YEAR')\rfor i in range(1,13):\rplot_month(i,data)\rplt.savefig('plot4.png', dpi=300, bbox_inches='tight')\rplt.show()\r# Month-wise Plot for Apparent Temperature of 10 years title = 'Month-wise Plot for Apparent Temperature of 10 years' sns_plot(title, TEMP_DATA)\rThis graph shows the changes in Temperature for each month from 2006 to 2016.\n# Month-wise Plot for Humidity of 10 years title = 'Month-wise Plot for Humidity of 10 years' sns_plot(title, HUM_DATA)\rThis graph shows the changes in Humidity for each month from 2006 to 2016.\nVariation of Humidity \u0026amp; Apparent Temperature for each months: Creating a function that helps to analyze the variations in Apparent Temperature and Humidity for each month over the 10 years.\n# Function for plotting variation for each month\rdef sns_month_plot(month):\rplt.figure(figsize=(15,7))\rlabel = label_color(month)[0]\rplt.title('Apparent Temperature Vs Humidity for {}'.format(label))\rdata = df_monthly_mean[df_monthly_mean.index.month == month]\rplt.xlabel('YEAR')\rsns.lineplot(data=data, marker='o')\rname=\u0026quot;month\u0026quot;+str(month)+\u0026quot;.png\u0026quot;\rplt.savefig(name, dpi=300, bbox_inches='tight')\rplt.show()\r# Plot for the month of 'January - December'\rfor month in range(1,13):\rsns_month_plot(month)\rThe graphs below show the variations in Apparent Temperature and Humidity for each month from 2006 to 2016.\nJanuary February March And so on.\nObservation:  As from the above plots, we can understand that, ‚ÄôThe Apparent Temperature‚Äô has a tremendous fluctuation over the time period. There is a sharp rise of temperature between year 2008‚Äì2009 which again decreases in year 2009‚Äì2010. It is observed that the average Apparent Temperature is at its peak in year 2009 which further drops to its lowest in year 2015. Whereas the average Humidity has remained nearly constant over the period of time.  Conclusion: From this analysis, We can conclude that the Apparent temperature and humidity compared monthly across 10 years of the data indicate an increase due to Global warming. This clears that our Null Hypothesis is having a True positive impact.\nMiscellaneous: You can do more analysis on the data, the more we question the data, the better we know about it. You can create more and more Hypothesis to verify more about your objective. You can also create a weather prediction model; using this data to train and test your model. It‚Äôs all up to you. That is one of the best thing about exploratory data analysis.\n","permalink":"https://sinanthahir.github.io/blogs/exp-weather-eda/","title":"Experience Analysis through Weather Data : Exploratory Data Analysis"},{"content":"","permalink":"https://sinanthahir.github.io/tags/matlab/","title":"Matlab"},{"content":"Matlab Modeling and Simulation : Cheat Sheet \u0026amp; Samples Matlab, is a high-performance language which assimilates computation, visualization and programming in a single environment. The name MATLAB stands for matrix laboratory. MATLAB was originally written to provide easy access to matrix software developed by the LINPACK and EISPACK projects, which together represent the state-of-the-art in software for matrix computation.\nMATLAB is an interactive system whose basic data element is an array that does not require dimensioning. This allows you to solve many technical computing problems, especially those with matrix and vector formulations, in a fraction of the time it would take to write a program in a scalar noninteractive language such as C or Fortran.\nMATLAB¬Æ is widely used in different areas of applied mathematics, in education and research and in numerous industries. This software finds its wide applications in different domains of engineering such as:\n Electronics engineers mainly use MATLAB¬Æ for designing more efficient devices that are smaller in size and can integrate wireless communications, audio, video, and other attributes. In electrical engineering, the application of this program is to examine and simulate momentary phenomena in power systems. Mechanical engineers need MATLAB¬Æ for scrutiny of problems in control systems, mechanical vibrations, basic engineering mechanics, electrical circuits, statics and dynamics and numerical methods. It is used to model and simulate physical problems in the field of chemical engineering.  Cheat Sheet Small variables like x and y will be either row or column vectors and A will always be a matrix.\nBasic Commands    Command Function     clc Clear command window   clear (all) Clear all variables   close all Close all plots   clf Clear all plots   doc command Extensive help page for command   help command Quick help page for command   %This is a command Indicates a comment   a=5; Semicolon suppress ouput   whos List all variables defined   disp('text') Print text   save 'file.mat' Save variables to file.mat   load 'file.mat' Load variables from file.mat   diary on Record input/output to file diary    Keyboard Shortcuts    Shortcuts Function     F1 Help/documentation for highlighted function   F5 Run Code   F9 Run highlighted code   F10 Run code line   F11 Run code line, enter functions   F12 Insert break point   Ctrl+D Open Highlighted codes file   Ctrl+R Comment code   Ctrl+T Uncomment code   Ctrl+N Open new script   Ctrl+W Close script   Ctrl+C Abort operation    Entries of Matrices and Vectors    Entries Function     abs(x) The absolute value of x   eps Floating point accuracy   1e6 10^6   sum(x) Sums elements in x   round Rounds to the nearest integer   ceil Rounds to the nearest integer greater than or equal to that element   fix Rounds to the nearest integer toward zero   floor Rounds to the nearest integer less than or equal to that element    Cell Manipulation    Manipulation Function     x = cell(a, b) a * b cell array   x{n,m} Access cell element n,m   cell2mat(x) Transforms cell to matrix    Manipulation of Variables    Manipulation Function     a=500 Define variables a to be 500   x=[3,1,4] Set x to be the row vector [3,1,4]   x=[3;1;4] Set x to be the column vector [3,1,4]^T   x(2)=7 Change x from [3,1,4] to [3,7,4]   A(2,1)=0 Change A`2,1 from 5 to 0    Basic Arithmetic and Functions    Operations Function     1*2,3+4,5-6,7/8 Multiply, add, subtract and divide   2^8 compute 2^8   sqrt(16) compute square root of 16   log(5) compute ln(5)   sin(2*pi/6) Compute sin(60)    Operations on Matrices and Vectors    Operations Function     x + 5 Add 5 to every element of x   x + y Elementwise addition of two vectors x and y   10 * y Multiply every element of y by 10   A * y Product of a matrix and vector   A * B Product of two matrices   A .* B Element-wise product of two matrices   A ^ 4 Square matrix A to the fourth power   A .^ 4 Every element of A to the fourth power   cos(A) Compute the cosine of every element of A   abs(A) Compute the absolute values of every element of A   A' Transpose of A   det(A) Compute the determinant of A   size(A) Get the size of A    Data Import \u0026amp; Export    Command Function     xlsread/xlswrite Spreadsheets (.xls,.xlsm)   load/save -ascii Text files (.txt,.csv)   load/save Matlab files (.m)   imread/imwrite Image files    Solving linear equations    Command Function     inv(A) Compute the inverse A^-1   eig(A) Compute the eigenvalue of A   [L,U,P] = lu(A) The LU factorization PA = LU   [V,D] = eig(A) V are the eigenvectors of A, and the diagonals diag(D) are the eigenvalues of A   A\\b Compute the solution x to Ax=b    Plotting    Command Function     plot(x,y) Plot y versus x   loglog(x,y) Plot y versus x on a log-log scale   semilogx(x,y) Plot y versus x with x on a log scale   axis equal Force the y and x axes to be scaled equally   title('A Title') Add a title to the plot   xlabel('x text') Add a label to the x axis   legend('foo', 'bar') Label two curves for the plot   grif on/off Add a grid to the plot   subplot(a,b,c) For multiple figures in one plot   hold on Retains current figure when adding new stuff   set(fig1, 'LineWidth', 2) Change line width   set(fig1, 'LineStyle', '-') Change to dot marker   set(fig1, 'Marker', '.') Change marker type    Debugging    Command Function     tic/toc Start/Stop Timer   try/catch Good to track errors   dbclear Clear breakpoints   break Terminate execution of for/while loop    Logicals a = 20; %Assign a the value of 10 a == 5 %Test if a is equal to 5 false a == 20 %Test if a is equal to 10 true a \u0026gt;= 5 %Test if a is greater than or equal to 5 true a 1 \u0026amp;\u0026amp; a ~= 10 %Test if a is greater than 1 AND false %not equal to 10 a \u0026gt; 1 || a ~= 5 %Test if a is great\rFor Loops for k = 1:10 disp(k); end\rConditional Statements if a \u0026gt; 90 disp('Greater than 90'); elseif a == 90 disp('a is 90'); else disp('None of the conditions is mets');\rend\rWhile Loops k = 0; while k \u0026lt; 5\rk = k + 1;\rend\rFunctions function [a, b] = testfct(x, y) a = x + y; b = x * y; end testfct(2, 3) %Call function in script or command window\rFunction Handles\rsqr = a(n) n.^2; x = sqr(3) %Outputs 9\rPlotting and Subplot x = linspace(-5*pi, 5*pi, 1000); y1 = sin(x); y2 = cos(x); plot(x, y1, 'g-', 'LineWidth',3); % Plot black sin(x) curve hold on % Adding additional curve plot(x, y2, 'r-', 'LineWidth',3); % Plot red cos(x) curve grid on set(gca,'fontsize',20) % Set the axis limits axis([-5*pi, 5*pi, -1.5, 1.5]) % Add axis labels xlabel('x', 'FontSize',20); ylabel('y', 'FontSize',20); % Add a title title('A plot of cos(x) and sin(x)', 'FontSize', 20); % Add a legend legend('sin(x)', 'cos(x)');\r----- % Code for Subplots x = linspace(0,10,50); y = rand(50,1); subplot(2,2,1), plot(x,sin(x),'Color','red','LineWidth',3) set(gca,'fontsize',14) axis([0,2*pi,-1,1]), axis square subplot(2,2,2), plot(x,cos(x),'Linewidth',3,'Color','blue') set(gca,'fontsize',14) axis([0,2*pi,-1,1]), axis square subplot(2,2,3:4) y2 = rand(50,1); plot(x,y2,'LineWidth',3) set(gca,'fontsize',14)\rThe resulting plot looks like : ","permalink":"https://sinanthahir.github.io/blogs/matlab-cheatsheet-simulation/","title":"Matlab Modeling and Simulation : Cheat Sheet \u0026 Samples"},{"content":"","permalink":"https://sinanthahir.github.io/tags/visualization/","title":"Visualization"},{"content":"","permalink":"https://sinanthahir.github.io/tags/community/","title":"Community"},{"content":"","permalink":"https://sinanthahir.github.io/tags/creator/","title":"Creator"},{"content":"","permalink":"https://sinanthahir.github.io/tags/idea-generation/","title":"Idea Generation"},{"content":"","permalink":"https://sinanthahir.github.io/tags/side-hustle/","title":"Side Hustle"},{"content":"You Should Start A Podcast : Effective Content Delivery Content creation and marketing comes in many different shapes and sizes nowadays. Creators are promoting their ideas through a lot of options like blog posts, social media updates, video visuals, slide decks and even more.\nBut the most effective, i will surely agree to audio content delivery.\nAudio is being used in clever ways to fit into the content delivery domain. Podcasts seem to be a more enriched way to reach more and direct a personal relationship with audience.\nWell-conceived podcasts are an effective, portable, convenient and intimate way to deliver and produce content, and to build ongoing relationships with your clients, employees and constituents.\nLet me tell you 4 Potential benefits of podcasts, i considered : 1. Podcasts make information personal. In a podcast, the content is communicated or delivered directly to you, the listener; that means verbally. That‚Äôs a much more intimate way of getting informed than reading a email or blog posts.\n2. Podcast is a time-efficient form of communication. You can listen to a podcast while do other activities, like at work or at home, even while your commute to places. I prefer podcast mostly because of this reason; while studying or working on projects, i usually listen to growth enhancers like Ted Talks Daily or On Purpose with Jay Shetty. Thus in favor of saving time and improving productivity, podcasts are apt.\n3. Podcast are convenient and easy to consume. Podcasts are delivered digitally and many more podcasting platforms are coming up since its demand increases, thus cuts down a lot of costs compare to video contents and print media. They can be easily archived and update quickly by the broadcaster. Once a listener subscribe to a podcast feed, new updates in content are automatically synced and listen to your convenience.\n4. Podcasting is an on-demand technology. Listeners decide what they want to hear, and when they want to hear it. On one hand, this means you‚Äôre competing for their eyes and ears. On the other hand, this means that if they are subscribing to your podcasts, there‚Äôs an excellent chance they‚Äôre actually getting the information you‚Äôre providing to them.\nNot the least, There are many more reasons to start Podcasting: 5. To build an audience. Just like with a blog, a podcast is a way for you to build an audience. As your podcast grows in popularity, the size of your audience increases. Not everyone who listens to your show will come back for more, but the ones who like your style and your content will become loyal listeners. They will recommend your show to others, and over time you will build a tribe of fans eager to hear your next episode.\n6. To increase the value and size of your network. If you host a podcast in which you interview various guests for your show, one of the most obvious benefit of doing so is that you get to expand your network. A podcast is a great platform to leverage to reach out to people you might not have been able to otherwise. As your audience grows in size, your ability to reach out to the high profile experts in your industry increases.\n7. You can make money from your show. A podcast doesn‚Äôt have to be a hobby. There are ways you can make money from your show. You can monetize your podcast. If your download numbers are high enough, you can charge sponsors to be mentioned on your show. You can also use your show to promote your own products or services (books, courses, or consulting, for example).\n‚ÄúDay by day, more and more industries are looking out for podcasters to promote and market there product on there podcast episodes. Because of the direct interaction with the listeners, results in more engagement and branding of there products. thus the opportunity of revenue may be least at the beginning but increases with your podcast growth.‚Äù\r\rHey there, people! I had recently launched a new podcast of my own, Spotify Podcast ‚Äî Bookyard Audiobook \u0026amp; Summaries. Bookyard is a Anchor hosted podcast which provides you with Audiobook Summaries from Books on Fiction, Growth and many more !\n I am book reader since mid-school, but i had a habit of pen down the summary of each book i read. but after the last two years of listening podcast ‚Äî i came up with idea of converting my hand written to audio summaries. thus by implementation of PDF to Voice format interpolation using Google Cloud : Text-to-Speech API, So that the summaries are converted to voice episodes for broadcasting.\n ‚ÄúThere was a lot technical aspects used. i will later come up with an article how i did begin my podcasting.‚Äù\r\r If you‚Äôve made it this far, congrats. That means you‚Äôre committed this. To reward you, I‚Äôve got something that‚Äôll make this process podcasting even easier. So Set-forward to start your own podcast. First of all, no one is like you. No one has the same experiences and stories to share. No one is going to podcast the way you do, and your vibe will attract your own tribe. We‚Äôre still in the early days of podcasting. So like I said, your timing is great.\nBelow, you‚Äôll find the step by step easy method for starting a podcast using just your mobile device. #1. Choose a Topic for your podcast. Write down a list of twenty-five potential ideas for the podcast topic(s) you have in mind. if possible like to engage in episode wise topics, potential guest names, too, you were going to interview those people.\n‚ÄúFor the fact, getting some one to listen your thoughts is the greatest asset in this busy world. So look for unique and relevant topics, rather than already existing ones.‚Äù\r\rYou don‚Äôt need to worry about the exact things ‚Äî just come up with unique ideas.\n#2. Pick a Show Title The title of your podcast is one of the first things people see, even before they listen to a single word of your show. So naturally, this is a really important decision. It defines your branding, your artwork, what you say, how you share it, and many many more things. Just thing;\nWho is the show for?\nThink about this question. The answer is not everyone. Who is your audience? Who do you want to reach?\r\r#3. Formatting your Podcast Formatting refers to What‚Äôs your podcast going to look like?. Podcasts can take many forms: one-man shows, co-hosts, guests, call-in, etc.\n I listen to a lot of podcasts and the most typical format is 2 or 3 hosts and sometimes one guest. I‚Äôve never subscribed to a single-person podcast before because I‚Äôve yet to find a single-person-talking podcast that is interesting enough to stick with‚Ä¶ Two or three people chattering to each other is the most common format but it‚Äôs possible to take it too far. Stick to 2‚Äì3 people on your show.\n #4. Get a Logo/Artwork Your podcast is going to need some artwork ‚Äî a square image that represents your show. As much as podcasting is an auditory medium, the graphical, visual element that represents your podcast plays an extremely important role.\nIt‚Äôs a really good idea to get a logo for your podcast. Sure, you could do it yourself on Canva if you really want. It‚Äôs all up to your choice.\n#5. Choose a Podcast Hosting Platform. As for me, before starting to recording episodes. I looked forward towards the best Podcast Hosting platform, and its diverse features. Sign up to a platform you wish, i wish is to join either Buzzsprout or Anchor.fm (check out the links to view the features).\nFor the last 6 months, i was using Anchor.fm . So i prefer to go with it.  In my instincts, Anchor provides a better user friendly mobile application with in built option for audio recording, sound library and episode. That means for beginners can even use your headphone or condenser mic to record podcast sessions and edit through there devices.\n #6. Recording, Uploading, and Promoting Before you press the record button, there are couple steps to prepare for your podcast.\nGear to get Started A quality podcast will mean quality equipment.Sure, you can scrape by with a bare minimum setup. You can record a podcast with nothing more than your smartphone, but it‚Äôll sound like just that ‚Äî a phone call recorded on a mobile device.\nBuy a microphone. Audio quality begins and ends with a microphone. The better microphone you buy, the sharper your podcast will sound. And audio quality reigns supreme when a person‚Äôs podcast choices include heavyweights like WNYC, NPR, and ESPN.\nIf your prefer in creating a professional podcast, take a look on the Podcast Insight‚Äôs Equipment List Invest enough to create a quality podcast, see if people like it, then advance from there.\r\rOutline A.K.A Scripts Your best bet for a podcast that sounds organized and professional is to practice beforehand by figuring out what you‚Äôre going to say and coming up with an outline for your recording. You don‚Äôt have to go so far as to script things out. Just have a road map for where you‚Äôre headed and what you want to touch on.\nHere‚Äôs a Sample Outline to Consider,  Show intro (30‚Äì60 sec) : who you are, what you‚Äôre going to talk about. Intro Jingle (30‚Äì60 sec) : repeat for each show, create a brand awareness for your show Topic 1 (3 min-10min, in case of multiple topics you opt; go for the least time with maximum content delivery) Interlude (30 sec) : music, break or ads Topic 2 (3 min-10min) Closing remarks (2 min) : thank audience, guests, give a glimpse about next show. Closing Jingle (1 min) : i suggest same as that of intro jingle.  (Note: If you have co-hosts, you might consider each of you recording your end of the conversation and stitching the separate audio files together in post-production. This makes for cleaner audio.)\r\r  After you‚Äôve finished recording, editing, and producing your podcast, you can upload it to hosting sites like Anchor, Buzzsprout and Soundcloud. Most of these platform performs distribution of your show to wide Podcast Directories like Google Podcasts, Breaker, Spotify, so on. Some of the Directories like Apple iTunes require manual submission.\nPromotion For promotion and sharing of your podcast, a lot will depend on the site where you upload. You can also share directly to Twitter, Facebook, and more, and you can embed the audio directly into your blog posts.\nEmbedding audio is perhaps the best way to sync your podcast with your blog content. Many top blogs use their podcast as an additional blog post, adding the audio directly into the body of the post and providing either a full transcript of the podcast or a list of topics and resources covered in the podcast.\r\rThe ideal everything for podcasts We get quite a kick out of learning the ideal length and frequency for a number of different types of content, and podcasting is no exception. There‚Äôs less research out there about podcasts, so what I couldn‚Äôt find, I ran the numbers myself from top-notch podcasts.\nMaintaining an ideal timing, frequency and duration of each episode can have a vital role in improving your podcast stats.\n#7. Monetize your Podcast The most common way podcasts make money is through advertising or sponsorships. Companies may pay you money to have you read off a script or talk about their company in different parts of your podcast episodes.\nThis can be very rewarding, but at the same time, it‚Äôs hard to find sponsors when your show is just starting out. They want to know people are going to listen before they pay you.\n I‚Äôd recommend starting with affiliate marketing (Amazon‚Äôs associate Program). that means you can generate income by recommending various product or by marketing your own product to the listeners. You can start with this kind of income generation from day 1, and even if you don‚Äôt have many listeners, a year from now when you do, you can see the clicks coming in.\n If you wish to know more tactics to grow and market your podcast show, take a look on: Opinions by 50 Podcasters on there Growth Formula.  I Appreciate You! I truly hope you enjoyed this tutorial about how to start a podcast.\nFeel free to share this with your friends and colleagues who you think could benefit from this, too.\nLastly, if you still feel you need more help, you are free to contact me!\nCheers, and I‚Äôll see you and your podcast very soon! ","permalink":"https://sinanthahir.github.io/blogs/podcast-effective-cdn/","title":"You Should Start A Podcast : Effective Content Delivery"},{"content":"Better Decision from Bitter Opinions ! Why criticism is good for you !\n Criticism means the expression of disagreement of someone or something that is based on perceived beliefs, faults and mistakes.\n Now the point is to consider whether it‚Äôs good or not. Taking criticism can be a difficult thing. Nobody likes to be told that something they have slaved over for days didn‚Äôt quite hit the mark. If we go by it‚Äôs meaning; to criticize someone is bad and even if you know some of your work probably deserved some extra love, criticism always stings.\nBut on the other hand, it may lead to improvement of the person being criticized and he becoming a better person, not repeating the mistakes again. At some point, even my writings ‚Äî are so dependant on reviews and opinions. Though one day you will encounter a customer or your audience and even a reviewer ‚Äî who wants to tell you how to do things better. But it‚Äôs not all bad news because sometimes you can use criticism to give you a competitive edge. It entirely depends upon the perceived value hidden behind the criticism.\nCriticism : a form of communication. If someone has a criticism for you; literally take it as they want to give you a feedback on what you are done or doing for them. We all make mistakes all the time, it is human nature. As we go through life we have plenty of opportunity to learn and improve ourselves. That means Criticism is an opportunity to learn more about the person who you‚Äôre working for and in case your a influencer or in business; how to convert them into a satisfied customer or audience member.\n‚ÄúAny fool can criticize, condemn, and complain but it takes character and self control to be understanding and forgiving.‚Äù ‚Äî Dale Carnegie\r\rGenerally speaking, there may be some truth behind each criticism you get; even it is given out on spite and bitterness. The criticism aimed at you may not make sense at the time, It is often the case that a slight change on your character is a fair reflection of how another person sees you at that point in time. So take a step-back, try to look from other‚Äôs perspective or ask the opinions of a honest friend, that will make you.\nCriticism : gives you a Competitive advantage. You cannot be sure whatever the critic is saying is right. Having heard him out, compare his statements or assessments with the facts on the ground. Sort out what is true from what is a biased statement and make objective analysis of them.\nThink about it : if you are a Salesperson and can get a customer to tell you ‚Äî and just you ‚Äî how to give them the perfect product or service, that‚Äôs information you‚Äôve got that no one else has. Even being a criticism too, the information you gets, puts you at an advantage over anyone else in your sector and can be used again in the future to get things right, even faster.\nIf you are open to suggestions around how you might approach things differently, you‚Äôll be perceived as a more authentic leader and it‚Äôll be easier for you to rally a team around a common goal or towards improving shared processes.\nThink Before Act. Don‚Äôt take it personally if someone doesn‚Äôt immediately like your work. Not everyone has pure motives when it comes to giving you feedback. If the criticism you‚Äôre receiving really stings, think about what that person is saying. Are they talking about something that directly influences the way you work or your behavior in a specific situation? Or are they more concerned about you come off as a person? The key thing to remember is that whatever the circumstance is, don¬¥t respond in anger as this will cause a scene and create bad feelings ‚Äî and possibly a bad image of you.\nRemember: when people tell you something‚Äôs wrong or doesn‚Äôt work for them, they are almost always right. When they tell you exactly what they think is wrong and how to fix it, they are almost always wrong. ‚Äî Neil Gaiman.\r\rThere will be occasions when you feel the criticism is personal and, now and then, you‚Äôll be right.If feedback is based on something intrinsic to your personality, it‚Äôs not important enough to worry about. Criticism needs to be partnered with a solution to help you correct the action. If it‚Äôs not, the person is not interested in helping enough to warrant getting involved, literally it‚Äôs enough for them to shut up.They are also able to make it work to their advantage or, if all else fails, politely conclude the partnership and leave with their reputation intact.\nUnsure of how effectively you‚Äôre communicating? Try to transform your critical phrases into feedback that inspires change. May these words help you along !\nAlas, Enjoy reading ! ","permalink":"https://sinanthahir.github.io/bookshelf/betterdecision-bitteropinions/","title":"Better Decision from Bitter Opinions !"},{"content":"Is it okay to show your flaws? When and how, i Fall in Love with My Flaws ! Most of us are taught to hide our flaws. the fact is that each one of us from the childhood to the very existence of life; try to preserve our flaws and insecurities. but not a single one of us is perfect. And that‚Äôs one of the great thing of the life. Not only we do have flaws, but each of us struggles with feeling flawed at some situations.\nBeing a student-entrepreneur, i too had many time flawed. All the adrenaline shot up in the head, at the time of brain-storming sections. As a core member, the idea‚Äôs or for the suggestion‚Äôs ‚Äî i need them intact or rather say; to be good. But for me, how to convey properly , or how to make others understand , all of a sudden such thoughts came to hit me, when standing in front of them. One of the colleague said, it was overthinking, that make me do so, but really need to appreciate her for hearing me out, cause overthinking is one of my flaws.\nYes ! Even now when i‚Äôm writing it, i‚Äôm indeed flawed! i don‚Äôt know how much my idea is going to lay impact on you. Now, you may be thinking me, being a dumb ass over-thinker; Haha, though some time these flaws really in-turns out to be good.\nFrankly at many times, these over-thoughts turned my strategic action very beneficial. That was the moment, made me to fall in love with my flaws. May be some of you had already accepted there flaws or some are still cliche to there flaws. To say, there will some times, when you really love it.\nLets talk about Wabi-Sabi. If my analogy hadn‚Äôt able to ‚Äòhit a hole‚Äô for you, lets try a different approach.\nIn Japanese culture, there is an art form known as wabi-sabi. It has been around for centuries. When a plate becomes chipped or cracked, it is not discarded like trash. The cracks are filled with metallic materials to accentuate their details. Wabi-sabi celebrates imperfections because no two are exactly the same. You possess that uniqueness in your own life, and you should be proud of what it‚Äôs helped you become.\nOf course we all know how difficult it is to accept flaws. It‚Äôs a difficult thing to do when it comes to other people and when it comes to ourselves, well, it‚Äôs can seem nearly impossible. But, hard as it might seem, it is possible to love even the most flaws and it‚Äôs much essential to live a positive present life.\nBut to live so, First learn to love yourself for who you are!\nLoving yourself means loving even the not-so-great parts of yourself. Learning to love your flaws is going to be a constant battle, but that is a worth a fight.\nSo lets get to know how to fall in love with your Flaw. 1. Look For Something you can do about it. Foremost, you need to check whether if the flaws troubling is something you can actually do something for it, in case of flaws like ‚Äî bad temper or wicked impatience should not be accepted instead should work on. It‚Äôs not like throwing up your hands and saying, ‚ÄúOh, that‚Äôs the way I am!‚Äù. Ask Yourself : Does the flaw negatively impact you and others? Is there anything I can do to change it?\n2. Determine your actually going to do something. Only you know and you only will know, deep down whether the flaw bugs you or not, now it‚Äôs time to be brutally honest with yourself. If you‚Äôve determined that a flaw is to be changed. You can change it, but will you ? If you know it needs to be changed and you‚Äôre going to put in the effort, awesome! Go for it!\n3. View it in other‚Äôs Perspective. We‚Äôre so close to our flaws that they seem so much larger to us, i.e magnified by our own perception. The things you see as horrible or offensive might not look so bad when you try seeing them from an outsider‚Äôs point of view. In your mind, take a step back and try to imagine from other‚Äôs perspective about the flaw. When it comes, consider and contemplate how you would react to it when it is spotted on someone else. There you gets the clear image of your flaw.\n4. Accept for really what it is. Last but not least, accept your flaw for exactly what it is. After viewing from other person view and understanding about the flaw, now it‚Äôs time to take one step further ‚Äî simply accept it for what it is. Don‚Äôt compare it to others or rate it on a scale of good/bad. Strip it from all internal judgments; Accept it for what it is and realize that it is a part of you. Your flaws make you who you are, so embrace them!\nNow you should be on the road to either changing or loving your flaws, these steps allowed me to accept my flaws. Only you will know which flaw you should be working on and which one you need to accept and love. Remember Everyone has something, may be many he or she is flawed. But only Some people proactively choose to accept and love them.\nBe one among them. Love Your Flaws !\n This article was first published on Medium dated Sep 25, 2020.\n ","permalink":"https://sinanthahir.github.io/bookshelf/fallinlovewithflaws/","title":"Is it okay to show your flaws ?"},{"content":"","permalink":"https://sinanthahir.github.io/tags/ai/","title":"AI"},{"content":"","permalink":"https://sinanthahir.github.io/tags/ar/","title":"AR"},{"content":"How Project Aria going to change everyday life : Facebook‚Äôs Wearable AR ‚Äú Augmented Reality ‚Äî Enhancing flow of everyday life ‚Äù\r\rFacebook‚Äôs Full AR glasses are much away from reaching to our hands, but had started there road-test mapping with Cluster of sensors or to particularly say a ‚ÄòSensory array‚Äô debut research device in Seattle and the San Francisco Bay Area. A group of 100 Facebook employees and others getting hands on these, testing and for the thrive for data collection. The company announced the news Wednesday at its virtual Facebook Connect conference.\nSo what is this PROJECT ARIA ? With Project Aria, Facebook‚Äôs Reality Labs is trying to vision a future device free flow into the everyday life expect for the pair of glasses. these are not just the ordinary glasses, but a Augmented Reality Wearable. As Facebook says these pair of glasses adds a 3D layer of useful, relevant and meaningful information on top of our physical world. they projects out examples like- ‚ÄúImagine calling a friend and chatting with their lifelike avatar across the table. Imagine a digital assistant smart enough to detect road hazards, offer up stats during a business meeting, or even help you hear better in a noisy environment‚Äù. It paves the way for doing the everyday task at a better way and opens up an entirely new way of moving through the world.\n  Oculus Quest 2 an advanced stand-alone VR headset, is one of the Facebook‚Äôs Current Immersive Product on the market. But there AR ambition are going much a further way; The company is looking forward in creating a spatial scan of the real word called Live Map which will in-turn creates a better relation with people and other objects, giving a sense to the device.\nBut Facebook‚Äôs Reality Lab envisions to provide a better connectivity with no look downs to your devices. They are looking to a world where the device itself disappears in to the flow of life. Thus Project Aria is a new research project that will help us build the first generation of wearable AR devices.\n  Facebook says ‚ÄúTo actually build glasses flexible enough to work for most face shapes and sizes, and create the software to support them, we still need several generations of breakthroughs, like systems to enhance audio and visual input, contextualized AI, and a lightweight frame to house it all‚Äù.\nA visionary research tool ! Facebook puts into light that ‚ÄòThe Project Aria glasses are not a consumer product, nor are they a prototype‚Äô but a step into the future step in AR efforts. They are looking forward for a research device that will help us understand how to build the software and hardware necessary for AR glasses.\n  The Project Aria glasses use sensors to capture video and audio from the wearer‚Äôs point of view, as well as eye movement and location data to help our engineers and programmers figure out how AR glasses can work in practice.but that information will be held on-device and not be seen by Facebook researchers before blurring the data of faces and sensitive information like car license plates.\nFacebook plans to train an AI Assistant adapted for the glasses usage through the smart spatial audio technology. they also plans in refining the Livemaps; which will provide a 3D array of data and be a backbone for navigation through these glasses.They are practically improving the concept of embodied AI through these glasses.\nAs the first test run is set offed, Project Aria glasses are initially be made available to a limited group of Facebook employees and contractors in the United States, trained in both where and when to use the device, and where and when not to. Project Aria is most definitely not an actual pair of smartglasses. It‚Äôs a ‚Äúsensor array‚Äù for those future glasses. Facebook‚Äôs post on Aria says it will have ‚Äúthe full sensor suite used in VR headsets for spatial awareness,‚Äù adding, ‚Äúthey also compute location from GPS, take high-res pictures, and capture multichannel audio and eye images‚Äù. But the intersection of the real world and the data-collecting challenges smartglasses pose sounds like an extremely tricky problem.\nPrivacy Matters ! Facebook is promising to take care with data on the glasses. The testers are reportedly being instructed on how to use these devices responsibly. But the glasses will be tested lots of public spaces. In privately owned public places they‚Äôre supposed to get consent before recording. The data being recorded is encrypted and then Facebook uses a ‚Äúsecure ingestion system to upload data from the devices to a separate, designated storage space, accessible only to researchers with approved access.‚Äù\nPublic-collected data will ‚Äúnot be used to inform the ads people see across Facebook‚Äôs apps,‚Äù Facebook‚Äôs Project Aria privacy guidelines say. But that also suggests that, eventually, information on AR headsets could be used to target ads. It would be dealt with in the near AR future amidst not now. You can view the privacy policy guidelines by Facebook.\nChallenges! Facebook say‚Äôs ‚ÄúThe biggest initial challenge they are facing is to finding a way to take all of the existing sensors necessary to make AR work, and fitting them on a pair of glasses that participants could actually wear.‚Äù not only the design specification but also a more number of problem to be solved like Heat dissipated from micro-computers used, better wireless connectivity provision, light weight frames, better battery life to run all day long, a framework for storing and indexing your virtual objects( virtual co-ordinates ) placed by the user to another user‚Äôs view, preparing a well developed navigation which see‚Äôs better and understand the surroundings ; as a wearable, the contrast ratio correction as moving from sun to dark workplaces, varying focal lengths suitable for various peoples, better field view even with the 3D layer infographics . As Bosworth says ‚ÄúThis is a playground of challenging problems‚Äù , yes purely a many number solution is yet need to be founded.\nLooking Forward Facebook in one hand is really looking for providing an evolutionary research in AR ‚Äî making a better flow in the everyday life. Though the privacy matters are really a complicated weird line, if it is from Facebook. However the Facebook‚Äôs view ‚Äúfor a world with fewer devices and more time spent enjoying moments with family and friends, where opportunity is defined by passions, not geography or circumstance‚Äù sounds like a better tomorrow .\nFor more details about Project Aria, Click here\n This article was also published in Medium. You can check out my Medium page too.\n ","permalink":"https://sinanthahir.github.io/blogs/project-aria-wearable-ar/","title":"How Project Aria going to change everyday life"},{"content":"","permalink":"https://sinanthahir.github.io/tags/research/","title":"Research"},{"content":"","permalink":"https://sinanthahir.github.io/tags/tech/","title":"Tech"},{"content":"AI and ML : Shaping the New Automotive Era ‚ÄúArtificial intelligence living in every vehicle will become our reality before you know it.‚Äù\nFrank Borman once said ‚ÄúExploration is really the essence of the human spirit.‚Äù\r\rSo there lies no mistake at all, we are exploring only at a very starting verge of AI and ML ‚Äòs potentials in the new era of industries. Many of the technologies like Data Science, Text Mining, Neural Networking and Machine Learning are partially embedded in e-commerce, financial and online social platforms. Soon it will show its much dominance in manufacturing and automotive sectors.\nDay by day the technology evolves, so does the automotive with its trends and discoveries. We can‚Äôt barely imagine a day without riding our own vehicle or hopping on some kind of public transport. From the recent AI developments proved that artificial intelligence will soon transform every device we‚Äôre using. That means even your vehicle too.\nMany people thoughts that AI application in Automotive means the creation of auto-driving cars, still more advancement can be taken up for a better user end product. So, let‚Äôs take a dive into what are the ways AI application evolves the automotive industry.\nDriver Assist AI-based driver assistants bring massive changes to the navigation and safety measures on the road. It is an easy aid for those in-experienced and diverted in middle of driving, but also enhances the communication between the car and its owner.\nWith a plenty of real-time monitoring sensors, these AI assist can check blind zones, measure the exact distance to objects, and prevent emergencies from happening thereby saving lives on the road. These Assist software, in-fact can alert the driver behavior through monitoring drivers sitting posture, eye closings and much more. The best part of such driver assist AI application functionality is that, it can be customized according to the driver‚Äôs needs ‚Äî Ambulances, fire engines, public transports and school buses each have its own peculiarities and AI can do all.\nAutopilot Driving Since some-what time, people actually rely on the driver assistance‚Äî entrusting their safety and well-being. The idea of self-driving cars isn‚Äôt new, it‚Äôs the rapid development in the field of Machine Learning and Artificial Intelligence made it possible. Although the fact of car driving its own and the actual driver becoming the passenger is shocking and feared by many. But thanks to Tesla and Waymo turns this fiction into an absolute inevitable reality.\nIt‚Äôs all about the big data AI should process while driving much what to be like an experienced driver; pressing the pedals and following the GPS tips is simply not enough. Hopefully the higher competition in this area and innovative developments in both AI and Automotive industries will really bring us some high-performing solutions in the nearest future.\nCloud and Connective The best application of cloud integration in the automotive industry is the car connectivity through an internet access/ Wlan on board. With these applications, the cars can connect to a network and even with other cars; transmitting the generated data to the cloud and accessing it, increases a lot benefits to all road users such as certain condition in each location, data to manufactures about vehicle evaluation and maintenance and much more.\nPlanned Maintenance From the gas indicators to the distance compiler, checking on every monitors and sensors; your car basically knows what is about to happen with AI running. Thus, Car Cloud Connectivity takes Maintenance to a whole new level.\nAI assistant with cloud integration; not only gathers the real-time data, but also stores every single record of data for future analytics and statistics. AI can analyse for Car performance and predict component failures, so vehicle manufacturers and owners can work proactively to avoid problems. Since it connects the manufacture to the consumer end increasing a more problem-solving environment.\nA seamless Cloud experience is now under construction named Volkswagen Cloud Experience by Microsoft and Volkswagen which intended in saving natural resources and increasing road safety while driving.\nIndividualized marketing The best thing about it is that AI in your car software doesn‚Äôt complicate the user experience whatsoever It can also provide drivers with location‚Äëbased information and personalized advertising to help them find the things they need. This puts companies into a position when they have to look for marketing channels that would not overwhelm their potential customers, and connected AI automotive assistants come in hand here.\nThe cloud platform with AI driven is in close with driver and able to analyze consumer preference, action on roads and stops. This help the big companies with data, that can really able to make predictive marketing campaigns and advertisements for capturing the target audience basing on the location and personal preferences. A driver can get instant notifications about sales or some good deals on his way while driving. The same goes with a low fuel level or a need to visit the service, the AI assistant will notify about the gas station and car service on the driver‚Äôs route.\nRisk Assessment Having access to driver‚Äôs recent life events, analyzing his actions in road and more can in turn make Artificial Intelligence to find out any typical future threats to the driver. Suck risk profiles are much accurate since AI take into account of low lifestyle factors too. So with the Combination of Insurance Industry with the Connected Car Cloud, the possibility of better service can be retained.\nAI and ML in Manufacturing The data generated by the many sensors now embedded in vehicles, extracted from the design and development phase through to testing and production to marketing and compiled from customer feedback are powerful sources of information. Their analysis and interpretation provide equally powerful levers for improvement in design, testing and maintenance; as well as for understanding user needs and expectations.\nRobotics in manufacturing isn‚Äôt new to anyone these days, however, the AI applications at car manufacturing are not that spread yet. Market leaders are currently occupied with these AI applied Robotics in manufacturing plants since the potential cost of implementation is high.\nSimilarly in the warehouse management, the most high-end car manufacturers also use robots to collect, move, and sort items shortening the manual labor, as well as take part in vehicle assembly building.Some robots can also detect inaccuracies and defects on the car surface The technology behind smart robots is called Simultaneous Localization and Mapping (SLAM) ‚Äî a computational method of constructing a map of an unknown environment and navigation in it. Some preset algorithm in robots are used in order in manufacturing wielding , exterior painting and so on, which drastically reduce manual labors and up-cycling time and rate of manufacturing.\nIn addition to these preset and movable robots, research are lead by many top-end manufacturing company look out for exoskeleton wearable industrial robots to protect human workers, making them a lot stronger while keeping their mobility at max. A working bay of car manufacture can lead to many potential hazards to the workers due to the heavy machinery and circuitry network, so such equipment is a huge step forward to a safer working bay. Examples of exoskeleton development are Hyundai Vest Exoskeleton (H-VEX) and Hyundai Vest Exoskeleton (H-CEX) actively used by Kia Motors at their factories.\nConclusion Day by day, there is a tremendous amount of automotive increase in every part of the world, for e.g. Asia has 141% more cars than it has a decade ago. As the more crowded the road , more will be the risk factors. Today‚Äôs Automotive industries cannot only rely on Quality and driver cautious. Artificial intelligence stack of improved technology for every car is a significant step towards our safety and positive experience for each car users of tomorrow.\n This article was also published in Medium. You can check out my Medium page too.\n ","permalink":"https://sinanthahir.github.io/blogs/ai-ml-new-autmotive-era/","title":"AI and ML : Shaping the New Automotive Era"},{"content":"","permalink":"https://sinanthahir.github.io/tags/automotive/","title":"Automotive"},{"content":"Write a book: At least one in your lifetime. You‚Äôll discover who you are; unless you‚Äôve tried it. Living in this world with 7.8 Billion others, you hear that number; each individual with there own life story and putting each one‚Äôs creativeness forward to paper in your solace; can actually be a relief and thus a new writer is born.\nWriting a book considered as a skill but for me it‚Äôs upskilling. Listen, everyone can be a writer. Each one of us have a story to share. In fact, more stories to put forward. But the truth to write these stories, first you need to start write. Here come the prior stepping stones‚Äì Dedication and Passion.\nBy its very nature, Writing is an introspective and thoughtful activity. You don‚Äôt have to complete a book in a month or two; take your time. The more time you take in writing, the more you experience. If you‚Äôre an amateur, starting to write ‚Äî go for your trajectory of life. Many people think they need to do something massive or be famous to write about their life, That‚Äôs not truth at all. The reason behind writing about your life is that you have a real story; something worth changing lives of others with your trial and tribulations.\nEven you aren‚Äôt ready for a memoir, thou still have a valuable piece of short influential timeline, experiences or the knowledge gained that can help others; can be pen downed. It‚Äôs hard to peek inside, one of the hardest things in our life is to look inside ourselves. The harder you self-reflect, the more you discover who you been these all time. It can be objected a time when we evaluate ourselves.\nNot to mention writing a memoir. The most important thing to write a book about yourself is to get really, really honest and dig into the raw and deep parts about yourself. Nobody wants a book about you that‚Äôs all sunshine and rainbows because that‚Äôs not real life.\nIf You‚Äôre writing about yourself, here are some tips.  Decide what you need to write about yourself or a part of it. Self-reflect your own life Specify the experiences you want to share Create a mind-map of experience to connect Take those ideas and starts to write an outline.  Through writing, you‚Äôll gain perspective towards what really matters you. It will also teach you, the unique value of your own willpower.\nWriting a book is a way to touch your thoughts, values, and motivations. This simple act of writing can perish to measure the depths of your discipline and efforts. Because, writing is cheaper than a therapy.\nAll that counts is that you get your first word on paper, and then a word after that. You owe it to yourself to explore your passion and write a book. When you‚Äôre writing about something you love, it won‚Äôt feel like work.\nNow comes the hectic, tasks of drafting and publishing.\n A shady statistic, only 1% of world population ever publishes a book.\n No matter what you write a book about, whether you published it or not; that you write will open the door to your inwards or for more ideas. You‚Äôll educate yourself on a broad array of ideas to tackle more obstacles, Life thrown at you.\nWriting a book is leaving your comfort zone. The only way you grow as a person is by forcing yourself to leave your comfort zone.\nTime to touch the sky‚Ää‚Äî‚Ääwrite a book yourselves. Discover who you really are.\n This article was original published on Medium dated Sep 15, 2020. If you can check my Medium space.\n ","permalink":"https://sinanthahir.github.io/bookshelf/writebook/","title":"Write a book: Atleast one in your lifetime."},{"content":"üëã Hello world! My name is Sinan Thahir. I\u0026rsquo;m currently working as a Research Analyst and a life long learner - mostly analytics and research in the field of data.\nInterested in the entire analytics spectrum and would love to work on ambitious projects with positive people. Besides loving my job and my side hustle, I love to read books, play video games and scribbling. Fan of English Premier League, Outdoor activities, Series/Anime and English literature.\nSince beginning my journey as a student; nearly for the last 6-7 years, I‚Äôve been deeply involved in the technology and business domain. As a fact ended up my path in Bachelors in Technology degree. But in the mean time Data \u0026amp; Analytics became a part of me.\nApart from these, I had done remote work for event agencies, consulted for startups, and collaborated with talented people in creating products for both business and consumer use as well as in research.\n For more details about my education and my past experiences, take a look at my timeline or resume.\n üê¶ Stay up to date with me @sinanthahir ","permalink":"https://sinanthahir.github.io/about/","title":"About"},{"content":"","permalink":"https://sinanthahir.github.io/categories/","title":"Categories"},{"content":"Setup \u0026amp; Tech Bag Some day to day digital space triggers! üéØ Ghoul mode pic.twitter.com/lTcFq0gnEn\n\u0026mdash; sin(x) (@sinanthahir) November 24, 2021    Samsung Wondertainment LED: Purely refurbished, pandemic and online classes had made me to adopt this chiller here, now a days mostly use for animes and binge watching.\n  MSI Modern 14): New and dynamic !, personal computer. 100% drop test passed; often from my bed.\n  Inspiron 15 3000: Mostly work related.\n  Cosmic Byte Comet Laptop Cooling Pad: Life saver, best banger for my hotty laps.\n  POCO X3 Pro: Primary device, value for money.\n  HP Slim Keyboard and Mouse: Second one in a row, true productivity booster!\n  JBL Tune 700BT: Best noise cancellation ever, suitable to avoide noisy cousins.\n  Lenovo HE05 W-Earphones: Pairs with my Poco X3, usually on commute.\n  Gods Azrel Laptop Backpack: Using for some time, worth a buy.\n  Podcast Indeed, during daily commutes!\n Philosophize This! - Stephen West On Purpose with Jay Shetty 100x Entrepreneur - Siddhartha Ahluwalia Masters in Business - Bloomberg Indian Silicon Valley - Jivraj Singh Sachar The Mallu Show - Rizwan Ramzan  Favourite Anime \u0026amp; Series About the Site   The site was built using Hugo, Tailwind CSS, PrismJS and deployed on Github Pages. All the theme design development was done by Kai Zheng.\n  ","permalink":"https://sinanthahir.github.io/nerd-stuff/","title":"Nerd Stuff"},{"content":"","permalink":"https://sinanthahir.github.io/series/","title":"Series"},{"content":"Some of my work are shown here.\n","permalink":"https://sinanthahir.github.io/showcase/","title":"Showcase"},{"content":"You can find my credentials here or at my LinkedIn\nReach out and lets have a coffee together, someday; you can connect me through: \r\r\r\r\r\rGmail icon\r\r\r \n","permalink":"https://sinanthahir.github.io/timeline/","title":"Timeline"}]